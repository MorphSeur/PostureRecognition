{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1bf58f-c3fb-47bb-a9dd-866cdc8f2da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame by Frame\n",
    "import cv2\n",
    "vidcap = cv2.VideoCapture(\"input/YDXJ0098.mp4\")\n",
    "success, image = vidcap.read()\n",
    "count = 0\n",
    "\n",
    "while success:\n",
    "    cv2.imwrite(\"input/frames/frame%d.jpg\" % count, image)\n",
    "    success, image = vidcap.read()\n",
    "    print('Read a new frame: ', success)\n",
    "    count += 1\n",
    "    print (count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855b697d-306f-434d-af93-dadb35237388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame Recognition\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from Detection.Utils import ResizePadding\n",
    "from DetectorLoader import TinyYOLOv3_onecls\n",
    "\n",
    "from PoseEstimateLoader import SPPE_FastPose\n",
    "from fn import draw_single\n",
    "\n",
    "from Track.Tracker import Detection, Tracker\n",
    "from ActionsEstLoader import TSSTG\n",
    "\n",
    "def preproc(image):\n",
    "    image = resize_fn(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "\n",
    "def kpt2bbox(kpt, ex=20):\n",
    "    return np.array((kpt[:, 0].min() - ex, kpt[:, 1].min() - ex,\n",
    "                     kpt[:, 0].max() + ex, kpt[:, 1].max() + ex))\n",
    "\n",
    "\n",
    "source = './input/YDXJ0098.mp4'\n",
    "detection_input_size = 1024\n",
    "pose_input_size = '224x160'\n",
    "pose_backbone = 'resnet50'\n",
    "save_out = \"./output/out28122021YDXJ0098.avi\"\n",
    "device = 'cuda'\n",
    "\n",
    "# DETECTION MODEL.\n",
    "inp_dets = detection_input_size\n",
    "detect_model = TinyYOLOv3_onecls(inp_dets, device=device)\n",
    "\n",
    "# POSE MODEL.\n",
    "inp_pose = pose_input_size.split('x')\n",
    "inp_pose = (int(inp_pose[0]), int(inp_pose[1]))\n",
    "pose_model = SPPE_FastPose(pose_backbone, inp_pose[0], inp_pose[1], device=device)\n",
    "\n",
    "# Tracker.\n",
    "max_age = 30\n",
    "tracker = Tracker(max_age=max_age, n_init=3)\n",
    "\n",
    "# Actions Estimate.\n",
    "action_model = TSSTG()\n",
    "\n",
    "resize_fn = ResizePadding(inp_dets, inp_dets)\n",
    "\n",
    "# outvid = False\n",
    "outvid = True\n",
    "codec = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "writer = cv2.VideoWriter(save_out, codec, 30, (inp_dets * 2, inp_dets * 2))\n",
    "\n",
    "fps_time = 0\n",
    "f = 0\n",
    "for x in range(1998):\n",
    "    path = \"./input/frames/frame\" + str(x) + \".jpg\"\n",
    "    # print(path)\n",
    "    frame = cv2.imread(path)\n",
    "    frame = preproc(frame)\n",
    "    print (\"shape \", frame.shape)\n",
    "\n",
    "    # Detect humans bbox in the frame with detector model.\n",
    "    detected = detect_model.detect(frame, need_resize=False, expand_bb=10)\n",
    "\n",
    "    # Predict each tracks bbox of current frame from previous frames information with Kalman filter.\n",
    "    tracker.predict()\n",
    "    # Merge two source of predicted bbox together.\n",
    "    for track in tracker.tracks:\n",
    "        det = torch.tensor([track.to_tlbr().tolist() + [0.5, 1.0, 0.0]], dtype=torch.float32)\n",
    "        detected = torch.cat([detected, det], dim=0) if detected is not None else det\n",
    "\n",
    "    detections = []  # List of Detections object for tracking.\n",
    "    if detected is not None:\n",
    "        # Predict skeleton pose of each bboxs.\n",
    "        poses = pose_model.predict(frame, detected[:, 0:4], detected[:, 4])\n",
    "\n",
    "        # Create Detections object.\n",
    "        detections = [Detection(kpt2bbox(ps['keypoints'].numpy()),\n",
    "                                np.concatenate((ps['keypoints'].numpy(),\n",
    "                                                ps['kp_score'].numpy()), axis=1),\n",
    "                                ps['kp_score'].mean().numpy()) for ps in poses]\n",
    "    tracker.update(detections)\n",
    "\n",
    "    # Predict Actions of each track.\n",
    "    for i, track in enumerate(tracker.tracks):\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "\n",
    "        track_id = track.track_id\n",
    "        bbox = track.to_tlbr().astype(int)\n",
    "        center = track.get_center().astype(int)\n",
    "\n",
    "        action = 'pending..'\n",
    "        clr = (0, 255, 0)\n",
    "        # Use 30 frames time-steps to prediction.\n",
    "        if len(track.keypoints_list) == 30:\n",
    "            pts = np.array(track.keypoints_list, dtype=np.float32)\n",
    "            out = action_model.predict(pts, frame.shape[:2])\n",
    "            action_name = action_model.class_names[out[0].argmax()]\n",
    "            \n",
    "            img = cv2.imread(path)\n",
    "            print(\"Load \", img.shape)\n",
    "            # img = cv2.resize(img, (1920, 1920))\n",
    "            # print(img.shape)\n",
    "            # img = draw_single(img, track.keypoints_list[-1])\n",
    "            # print('1111111111111111')\n",
    "            name = str(action_name) + \" : \" + str(out[0].max() * 100)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(img, name, (15, 15), font, 0.5, (255, 255, 255), 1)\n",
    "            r = cv2.imwrite(\"./input/framesRec2/frameRec\" + str(x) + \".jpg\", img)\n",
    "            print(\"./input/framesRec2/frameRec\" + str(x) + \".jpg\")\n",
    "            print(\"is stored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a205857-2610-4c74-9a99-5a0e87d0599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frames Building\n",
    "import cv2\n",
    "\n",
    "img_array = []\n",
    "\n",
    "def toCheck(frame):\n",
    "    x = 0\n",
    "    if frame is None:\n",
    "        return None\n",
    "\n",
    "def openFrame(x):\n",
    "    path = \"./input/framesRec2/frameRec\" + str(x) + \".jpg\"\n",
    "    frame = cv2.imread(path)\n",
    "    return frame\n",
    "    \n",
    "for x in range(1998):\n",
    "    frame = openFrame(x)\n",
    "    if frame is None:\n",
    "        x += 1\n",
    "        print (x)\n",
    "        toCheck(frame)\n",
    "    else:   \n",
    "        height, width, layers = frame.shape\n",
    "        size = (width, height)\n",
    "        img_array.append(frame)\n",
    "\n",
    "        output = cv2.VideoWriter('./output/28122021RecFrames.avi', cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    "\n",
    "for i in range(len(img_array)):\n",
    "    output.write(img_array[i])\n",
    "output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8f814e-0a07-4ba9-9b04-23b9e4034eee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
